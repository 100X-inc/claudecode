# Anthropic公式: エージェント開発ベストプラクティス

Anthropic公式ドキュメント・GitHubから収集したエージェント開発のベストプラクティスをまとめたリファレンス。

## 公式リソース一覧

| リソース | URL |
|---------|-----|
| Building Effective Agents | https://www.anthropic.com/research/building-effective-agents |
| Claude Code Best Practices | https://www.anthropic.com/engineering/claude-code-best-practices |
| Writing Tools for Agents | https://www.anthropic.com/engineering/writing-tools-for-agents |
| Context Engineering | https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents |
| Long-Running Agents | https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents |
| Safe Agent Framework | https://www.anthropic.com/news/our-framework-for-developing-safe-and-trustworthy-agents |
| Agent SDK (Python) | https://github.com/anthropics/claude-agent-sdk-python |
| Agent SDK (TypeScript) | https://github.com/anthropics/claude-agent-sdk-typescript |
| Anthropic Cookbook - Agents | https://github.com/anthropics/anthropic-cookbook/tree/main/patterns/agents |

---

## 1. 基本原則

### シンプルさを優先

> "LLMを使ったアプリケーションを構築する際は、可能な限りシンプルな解決策を見つけ、必要な場合にのみ複雑さを増すことを推奨します。エージェントシステムを構築しないことがベストな場合もあります。"

**推奨アプローチ:**
1. まずLLM APIを直接使用（多くのパターンは数行で実装可能）
2. フレームワークを使う場合は、基盤となるコードを理解する
3. 複雑さは、性能向上が実証された場合にのみ追加

### ワークフロー vs エージェント

| 種類 | 定義 | 特徴 |
|------|------|------|
| **ワークフロー** | LLMとツールが事前定義されたコードパスで連携 | 予測可能、デバッグしやすい |
| **エージェント** | LLMが自身のプロセスとツール使用を動的に制御 | 柔軟、複雑なタスクに対応 |

**エージェントを使うべき場面:**
- ステップ数が予測不可能な問題
- 固定パスでは対応できないタスク
- 人間のように試行錯誤が必要な作業

---

## 2. コアワークフローパターン

Anthropicが推奨する5つの基本パターン:

### 2.1 プロンプトチェーン (Prompt Chaining)

タスクを逐次的なステップに分解し、各LLM呼び出しが前の出力を処理する。

```
[入力] → [LLM 1] → [LLM 2] → [LLM 3] → [出力]
```

**適用場面:** 固定サブタスクで精度が速度より重要な場合

### 2.2 ルーティング (Routing)

入力を分類し、専門化されたハンドラに振り分ける。

```
[入力] → [分類器] → [ハンドラA] または [ハンドラB]
```

**メリット:**
- 関心の分離
- シンプルなクエリを小さいモデルにルーティングしてコスト最適化

### 2.3 並列化 (Parallelization)

**セクショニング:** 独立した並列サブタスク
**投票:** 複数の試行で信頼性を向上

```
         ┌→ [LLM A] ─┐
[入力] ──┼→ [LLM B] ──┼→ [統合] → [出力]
         └→ [LLM C] ─┘
```

### 2.4 オーケストレータ-ワーカー (Orchestrator-Workers)

中央のLLMが予測不可能なタスクを動的に分解し、ワーカーLLMに委任。

```
                    ┌→ [ワーカー1] ─┐
[入力] → [オーケストレータ] ─┼→ [ワーカー2] ──┼→ [統合] → [出力]
                    └→ [ワーカー3] ─┘
```

**適用場面:** 複雑でオープンエンドな問題

### 2.5 評価者-最適化 (Evaluator-Optimizer)

一方のLLMが応答を生成し、別のLLMが反復的なフィードバックを提供。

```
[入力] → [生成LLM] ⟷ [評価LLM] → [出力]
              └──── フィードバックループ ────┘
```

---

## 3. ツール設計のベストプラクティス

### 3.1 基本原則

> "ツールはエージェント実行の主要な構成要素。ツールはClaudeのコンテキストウィンドウで目立つ位置にあり、タスク完了方法を決定する際の主要なアクションとなる。"

**設計ポイント:**
- すべてのAPIエンドポイントをラップしない
- 高インパクトなワークフローに焦点を当てた、少数の考え抜かれたツールを構築
- 複数操作を統合可能（例: `list_users` + `list_events` + `create_event` → `schedule_event`）

### 3.2 名前空間 (Namespacing)

明確な接頭辞で整理:

```
# サービス別
asana_search, jira_search

# リソース別
asana_projects_search, asana_users_search
```

### 3.3 レスポンス設計

| 悪い例 | 良い例 |
|--------|--------|
| UUID: `a1b2c3d4-e5f6...` | 意味のある名前: `"Project Alpha"` |
| 技術的ID | 自然言語の説明 |
| 固定フォーマット | `response_format`パラメータで柔軟に |

### 3.4 トークン効率

- ページネーション、フィルタリング、切り捨てを実装
- Claude Codeはデフォルトで25,000トークンに制限
- 広範な検索より、ターゲットを絞った検索を推奨

### 3.5 エラーメッセージ

```
# 悪い例
Error: 400 Bad Request

# 良い例
Error: Invalid date format. Expected YYYY-MM-DD, received "2024/01/15".
Example: {"date": "2024-01-15"}
```

---

## 4. コンテキストエンジニアリング

### 4.1 定義

> "コンテキストエンジニアリングとは、推論中にLLMが利用可能なトークンのキュレーションと管理を指す。"

**指針:** 望む結果の可能性を最大化する、最小限の高信号トークンセットを見つける

### 4.2 戦略

#### システムプロンプト

- 具体性と柔軟性のバランス
- シンプルで直接的な言語
- 脆いハードコードロジックを避ける

#### Few-Shotの例

- 多数のエッジケースを列挙するより
- エージェントの期待される振る舞いを効果的に描写する、多様で代表的な例をキュレート

### 4.3 長期実行テクニック

#### コンパクション (Compaction)

コンテキスト制限に近づいたら会話履歴を要約:
- 保持: アーキテクチャ決定、未解決バグ、実装詳細
- 破棄: 冗長な出力

#### 構造化されたノートテイキング

```markdown
# NOTES.md
- [決定] 認証にJWTを使用
- [TODO] エラーハンドリングの改善
- [バグ] ユーザー削除時の競合状態
```

#### サブエージェントアーキテクチャ

- 特化したサブエージェントがクリーンなコンテキストで集中タスクを処理
- 凝縮された要約（通常1,000-2,000トークン）を調整エージェントに返却

---

## 5. 長時間実行エージェント

### 5.1 主な課題

> "長時間実行エージェントは複数のコンテキストウィンドウにまたがると苦戦する。新しいセッションは以前の記憶なしに開始されるため。"

### 5.2 解決策: 2パートアプローチ

#### 初期化エージェント（最初のセッションのみ）

1. `init.sh`スクリプトのセットアップ
2. `claude-progress.txt`の作成
3. 初期gitコミット
4. 機能リストの生成（"failing"マーク付き）

#### コーディングエージェント（後続セッション）

1. 一度に1機能ずつ作業
2. 進捗ファイルとgitログを読んでコンテキスト理解
3. 説明的なメッセージでコミット
4. セッション終了前に進捗ドキュメント更新

### 5.3 一般的な失敗モードと対策

| 問題 | 解決策 |
|------|--------|
| 早すぎる完了宣言 | 明示的な完了検証を要求する機能リスト |
| 中途半端な実装 | gitコミット + 進捗ファイルでクリーンな状態維持 |
| 不完全なテスト | ブラウザ自動化ツールでE2E検証 |
| アプリ起動に時間がかかる | 事前作成の`init.sh`スクリプト |

---

## 6. 安全で信頼できるエージェント

Anthropicの5つの原則:

### 6.1 人間の制御と自律性のバランス

> "人間は目標の追求方法を制御し続けるべき。特に重要な決定の前は。"

**実装:**
- デフォルトで読み取り専用権限
- システム変更前に承認を必須化

### 6.2 行動の透明性

- 推論プロセスを説明
- リアルタイムのTo-Doチェックリストで計画を表示
- 人間が監視・介入できるようにする

### 6.3 価値観の整合性

> "自律システムは、システムにとって合理的に見えるが人間が実際に望んでいないアクションを取る可能性がある。"

### 6.4 プライバシー保護

- 部門間での不適切な情報転送を防止
- MCPで一回限りまたは永続的なアクセス許可を制御

### 6.5 セキュリティ強化

- プロンプトインジェクション攻撃を検出する分類器
- 継続的な脅威モニタリング
- MCPツールのセキュリティ・安全性基準

---

## 7. Claude Agent SDK

### 7.1 概要

Claude Agent SDKは、Claude Codeを動かすのと同じツール、エージェントループ、コンテキスト管理をプログラマブルに提供。

**利用可能:**
- Python: `claude-agent-sdk-python`
- TypeScript: `claude-agent-sdk-typescript`

### 7.2 主な機能

#### コンテキスト収集
- Bashコマンド（grep, tail）を使ったエージェント検索
- セマンティック検索
- サブエージェントによる並列化と分離されたコンテキスト
- 自動コンテキストコンパクション

#### アクション能力
- カスタムツール
- Bash/スクリプト実行
- コード生成
- MCP統合（Slack, GitHub, Google Drive, Asana）

### 7.3 検証ループ

エージェントは自身の作業を評価すべき:

| 方法 | 用途 |
|------|------|
| ルールベースフィードバック | コードリンティング、メール検証 |
| ビジュアルフィードバック | HTMLレンダリング、UI検証 |
| LLM-as-judge | トーンマッチングなど曖昧な基準 |

---

## 8. 実践的なワークフロー

### 8.1 探索-計画-コード-コミット

1. **探索:** Claudeに関連ファイルを読ませる（まだコードを書かない）
2. **計画:** 詳細な実装計画を要求（思考フレーズを使用）
3. **コード:** ソリューションをコード化、定期的に検証
4. **コミット:** コミットとドキュメント更新を依頼

> ステップ1-2をスキップすると、最適でない解決策につながることが多い。

### 8.2 テスト駆動開発 (TDD)

```
1. 期待する入出力に基づいてテストを書く
2. テストが実装なしで失敗することを確認
3. テストスイートをコミット
4. 全テストが通るまでClaudeにコードを書かせる
5. 動作するコードをコミット
```

> "Claudeは具体的なターゲットに対して最も良いパフォーマンスを発揮する—テストは測定可能な成功基準を提供する。"

### 8.3 拡張思考の活用

思考の深さを制御するフレーズ:

```
"think" < "think hard" < "think harder" < "ultrathink"
```

これにより、コードを書く前に代替案を評価させる。

---

## 9. 評価とイテレーション

### 9.1 強力な評価タスクの特徴

- リアルワールドの複雑さ（内部ナレッジベース、マイクロサービス）
- 複数のツール呼び出し（数十に及ぶ可能性）
- 明確な検証基準
- オーバーフィッティングを防ぐホールドアウトテストセット

### 9.2 評価タスクの例

> "顧客ID 9182が三重課金を報告。関連するすべてのログエントリを見つけ、他の顧客も影響を受けたか判断せよ。"

### 9.3 継続的改善

- パフォーマンスを継続的に測定
- 成果が実証される場合にのみ複雑さを追加
- 本番デプロイ前に広範なサンドボックステスト
- 自律システムに適切なガードレールを維持

---

## 参考: Anthropic Cookbook コード例

GitHub: https://github.com/anthropics/anthropic-cookbook/tree/main/patterns/agents

### 利用可能なノートブック

| ノートブック | 内容 |
|-------------|------|
| `basic_workflows.ipynb` | プロンプトチェーン、ルーティング、並列化 |
| `evaluator_optimizer.ipynb` | 評価者-最適化パターン |
| `orchestrator_workers.ipynb` | オーケストレータ-ワーカーパターン |

---

## まとめ: 3つのコア実装原則

1. **シンプルさ:** エージェント設計を簡潔に保つ
2. **透明性:** 計画ステップを明示的に表示
3. **ドキュメント:** ツール設計を通じてエージェント-コンピュータインターフェース（ACI）を丁寧に作り込む

---

*最終更新: 2026-01-13*
*情報源: Anthropic公式ドキュメント・GitHub*
